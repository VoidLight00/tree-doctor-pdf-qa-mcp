#!/usr/bin/env python3
"""
ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œ PDFë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
markitdown ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ ë²„ì „
"""
import os
import sys
import json
import re
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# markitdown ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/Users/voidlight/voidlight-markdown-mcp-server/src')

try:
    from markitdown_mcp_enhanced.core.markitdown import MarkItDown
except ImportError:
    logger.error("markitdownì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ markitdownì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    try:
        from markitdown import MarkItDown
    except ImportError:
        logger.error("markitdown ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install markitdown")
        sys.exit(1)

class ExamQuestionParser:
    """ì‹œí—˜ ë¬¸ì œ íŒŒì„œ"""
    
    def __init__(self):
        self.markitdown = MarkItDown()
        self.question_pattern = re.compile(
            r'(\d+)\.\s*(.+?)(?=(?:\d+\.\s|ì •ë‹µ|í•´ì„¤|$))', 
            re.DOTALL | re.MULTILINE
        )
        self.choice_pattern = re.compile(
            r'([â‘ â‘¡â‘¢â‘£â‘¤])\s*(.+?)(?=[â‘ â‘¡â‘¢â‘£â‘¤]|ì •ë‹µ|í•´ì„¤|$)', 
            re.MULTILINE
        )
        self.answer_pattern = re.compile(
            r'ì •ë‹µ\s*[:ï¼š]?\s*([â‘ â‘¡â‘¢â‘£â‘¤\d]+)'
        )
        self.explanation_pattern = re.compile(
            r'í•´ì„¤\s*[:ï¼š]?\s*(.+?)(?=\d+\.|ë¬¸ì œ|$)', 
            re.DOTALL
        )
        
    def extract_exam_round(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ íšŒì°¨ ì¶”ì¶œ"""
        match = re.search(r'ì œ(\d+)íšŒ', filename)
        return match.group(1) if match else "Unknown"
    
    def parse_questions(self, text: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œ íŒŒì‹±"""
        questions = []
        
        # í˜ì´ì§€ êµ¬ë¶„ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬
        text = re.sub(r'-+\s*Page \d+\s*-+', '', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # ë¬¸ì œ ì°¾ê¸°
        matches = list(self.question_pattern.finditer(text))
        
        for i, match in enumerate(matches):
            question_num = match.group(1)
            question_content = match.group(2).strip()
            
            # ë¬¸ì œì˜ ì „ì²´ ë²”ìœ„ í™•ì¸
            start_pos = match.start()
            if i < len(matches) - 1:
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(text)
            
            question_text = text[start_pos:end_pos]
            
            # ì„ íƒì§€ ì¶”ì¶œ
            choices = {}
            for choice_match in self.choice_pattern.finditer(question_text):
                choice_num = choice_match.group(1)
                choice_text = choice_match.group(2).strip()
                choices[choice_num] = choice_text
            
            # ì •ë‹µ ì¶”ì¶œ
            answer_match = self.answer_pattern.search(question_text)
            answer = answer_match.group(1) if answer_match else "ë¯¸í™•ì¸"
            
            # í•´ì„¤ ì¶”ì¶œ
            explanation_match = self.explanation_pattern.search(question_text)
            explanation = explanation_match.group(1).strip() if explanation_match else ""
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self.extract_keywords(question_content + " " + explanation)
            
            questions.append({
                'number': int(question_num),
                'question': question_content,
                'choices': choices,
                'answer': answer,
                'explanation': explanation,
                'keywords': keywords
            })
            
        return questions
    
    def extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ë³‘ì¶©í•´ ê´€ë ¨
        if re.search(r'ë³‘í•´|ì¶©í•´|ë³‘ì¶©í•´|ë³‘ì›ê· |í•´ì¶©|ë°©ì œ', text):
            keywords.append('ë³‘ì¶©í•´')
        
        # ìˆ˜ëª© ê´€ë¦¬
        if re.search(r'ì „ì •|ê°€ì§€ì¹˜ê¸°|ì „ì§€|ìˆ˜í˜•|ì •ì§€', text):
            keywords.append('ìˆ˜ëª©ê´€ë¦¬')
        
        # ì§„ë‹¨
        if re.search(r'ì§„ë‹¨|ì¦ìƒ|ë³‘ì§•|í‘œì§•|í”¼í•´', text):
            keywords.append('ì§„ë‹¨')
        
        # í† ì–‘
        if re.search(r'í† ì–‘|pH|ë¹„ë£Œ|ì˜ì–‘|ì‹œë¹„', text):
            keywords.append('í† ì–‘')
        
        # ë†ì•½
        if re.search(r'ë†ì•½|ì‚´ì¶©ì œ|ì‚´ê· ì œ|ì•½ì œ|ë°©ì œì œ', text):
            keywords.append('ë†ì•½')
        
        # ìƒë¦¬
        if re.search(r'ìƒë¦¬|ìƒì¥|ìƒìœ¡|ëŒ€ì‚¬|ê´‘í•©ì„±', text):
            keywords.append('ìƒë¦¬')
        
        # ìˆ˜ì¢… ì¶”ì¶œ
        tree_species = re.findall(
            r'(ì†Œë‚˜ë¬´|ì£ë‚˜ë¬´|ì€í–‰ë‚˜ë¬´|ëŠí‹°ë‚˜ë¬´|ë²šë‚˜ë¬´|ë‹¨í’ë‚˜ë¬´|ì°¸ë‚˜ë¬´|ë°¤ë‚˜ë¬´|ê°ë‚˜ë¬´|ë°°ë‚˜ë¬´|ì‚¬ê³¼ë‚˜ë¬´|ë³µìˆ­ì•„ë‚˜ë¬´)', 
            text
        )
        keywords.extend(list(set(tree_species)))
        
        # ë³‘ëª… ì¶”ì¶œ
        diseases = re.findall(
            r'(í˜¹ë³‘|íƒ„ì €ë³‘|í°ê°€ë£¨ë³‘|ìë§ˆë¦„ë³‘|ë¿Œë¦¬ì©ìŒë³‘|ì¤„ê¸°ì©ìŒë³‘|ëª¨ì˜ë¡ë³‘|ì—­ë³‘|ë…¹ë³‘|ì ë¬´ëŠ¬ë³‘)', 
            text
        )
        keywords.extend(list(set(diseases)))
        
        # í•´ì¶©ëª… ì¶”ì¶œ
        pests = re.findall(
            r'(ë‚˜ë°©|ì§„ë”§ë¬¼|ê¹ì§€ë²Œë ˆ|ì‘ì• |êµ¼ë²µì´|í•˜ëŠ˜ì†Œ|ë°”êµ¬ë¯¸|ë§¤ë¯¸ì¶©|ë‚˜ë¬´ì¢€)', 
            text
        )
        keywords.extend(list(set(pests)))
        
        return list(set(keywords))
    
    def process_pdf(self, pdf_path: str, output_path: str) -> Dict:
        """PDF íŒŒì¼ ì²˜ë¦¬"""
        logger.info(f"ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        
        try:
            # markitdownìœ¼ë¡œ PDF ë³€í™˜
            result = self.markitdown.convert(pdf_path)
            
            if not result or not result.text_content:
                raise Exception("PDF ë³€í™˜ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # íšŒì°¨ ì¶”ì¶œ
            exam_round = self.extract_exam_round(pdf_path)
            
            # ë¬¸ì œ íŒŒì‹±
            questions = self.parse_questions(result.text_content)
            
            # ë§ˆí¬ë‹¤ìš´ ìƒì„±
            markdown_content = self.generate_markdown(exam_round, questions)
            
            # íŒŒì¼ ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            logger.info(f"ì €ì¥ ì™„ë£Œ: {output_path}")
            
            return {
                'exam_round': exam_round,
                'total_questions': len(questions),
                'output_file': output_path,
                'success': True
            }
            
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'exam_round': self.extract_exam_round(pdf_path),
                'error': str(e),
                'success': False
            }
    
    def generate_markdown(self, exam_round: str, questions: List[Dict]) -> str:
        """ë§ˆí¬ë‹¤ìš´ ì»¨í…ì¸  ìƒì„±"""
        content = f"# ë‚˜ë¬´ì˜ì‚¬ ì œ{exam_round}íšŒ ê¸°ì¶œë¬¸ì œ\n\n"
        content += f"**ì´ ë¬¸ì œ ìˆ˜**: {len(questions)}ê°œ\n"
        content += f"**ì¶”ì¶œ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        content += "---\n\n"
        
        for q in sorted(questions, key=lambda x: x['number']):
            content += f"## ë¬¸ì œ {q['number']}\n\n"
            content += f"**ë¬¸ì œ**: {q['question']}\n\n"
            
            if q['choices']:
                content += "**ì„ íƒì§€**:\n"
                for num in ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤']:
                    if num in q['choices']:
                        content += f"- {num} {q['choices'][num]}\n"
                content += "\n"
            
            content += f"**ì •ë‹µ**: {q['answer']}\n\n"
            
            if q['explanation']:
                content += f"**í•´ì„¤**: {q['explanation']}\n\n"
            
            if q['keywords']:
                content += f"**í‚¤ì›Œë“œ**: {', '.join(q['keywords'])}\n\n"
            
            content += "---\n\n"
        
        return content

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡
    files = [
        {
            'input': '/Users/voidlight/Downloads/[Codekiller]ì œ5íšŒ ê¸°ì¶œë¬¸ì œ í•´ì„¤ì§‘(v1.0).pdf',
            'output': '/Users/voidlight/tree-doctor-pdf-qa-mcp/data/exam-5th-ocr.md'
        },
        {
            'input': '/Users/voidlight/Downloads/[Codekiller]ì œ6íšŒ ê¸°ì¶œë¬¸ì œ í•´ì„¤ì§‘(v1.0).pdf',
            'output': '/Users/voidlight/tree-doctor-pdf-qa-mcp/data/exam-6th-ocr.md'
        },
        {
            'input': '/Users/voidlight/Downloads/[Codekiller]ì œ7íšŒ ê¸°ì¶œë¬¸ì œ í•´ì„¤ì§‘(v1.0).pdf',
            'output': '/Users/voidlight/tree-doctor-pdf-qa-mcp/data/exam-7th-ocr.md'
        }
    ]
    
    parser = ExamQuestionParser()
    results = []
    
    for file_info in files:
        if not os.path.exists(file_info['input']):
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_info['input']}")
            continue
        
        result = parser.process_pdf(file_info['input'], file_info['output'])
        results.append(result)
    
    # ê²°ê³¼ ë³´ê³ 
    print("\n=== PDF ë³€í™˜ ê²°ê³¼ ìš”ì•½ ===")
    for result in results:
        if result['success']:
            print(f"âœ… ì œ{result['exam_round']}íšŒ: {result['total_questions']}ë¬¸ì œ ì¶”ì¶œ ì™„ë£Œ")
            print(f"   ì €ì¥ ìœ„ì¹˜: {result['output_file']}")
        else:
            print(f"âŒ ì œ{result['exam_round']}íšŒ: ë³€í™˜ ì‹¤íŒ¨ - {result.get('error', 'Unknown error')}")
    
    # ì „ì²´ ë³´ê³ ì„œ ì €ì¥
    report_path = '/Users/voidlight/tree-doctor-pdf-qa-mcp/data/conversion_report.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {report_path}")

if __name__ == "__main__":
    main()