#!/usr/bin/env python3
"""
ì œ5íšŒ ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œ ì™„ë²½ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
ì—¬ëŸ¬ PDF ì¶”ì¶œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¡°í•©í•˜ì—¬ ìµœìƒì˜ ê²°ê³¼ ë„ì¶œ
"""
import os
import sys
import subprocess
import json
import re
from datetime import datetime

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
libraries = [
    'pdfplumber',
    'pypdf2', 
    'pdfminer.six',
    'camelot-py[cv]',
    'tabula-py'
]

for lib in libraries:
    try:
        if lib == 'pdfminer.six':
            __import__('pdfminer')
        elif lib == 'camelot-py[cv]':
            __import__('camelot')
        elif lib == 'tabula-py':
            __import__('tabula')
        else:
            __import__(lib.replace('-', '_').lower())
    except ImportError:
        print(f"{lib} ì„¤ì¹˜ ì¤‘...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", lib])

import pdfplumber
import PyPDF2
from pdfminer.high_level import extract_text
from pdfminer.layout import LAParams
import camelot
import tabula

def extract_with_pdfminer(pdf_path):
    """PDFMinerë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        print("PDFMinerë¡œ ì¶”ì¶œ ì¤‘...")
        # í•œêµ­ì–´ PDFì— ìµœì í™”ëœ íŒŒë¼ë¯¸í„°
        laparams = LAParams(
            line_overlap=0.5,
            char_margin=2.0,
            word_margin=0.1,
            boxes_flow=0.5,
            detect_vertical=True,
            all_texts=True
        )
        
        text = extract_text(pdf_path, laparams=laparams)
        return text
    except Exception as e:
        print(f"PDFMiner ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None

def extract_tables_with_camelot(pdf_path):
    """Camelotì„ ì‚¬ìš©í•œ í…Œì´ë¸” ì¶”ì¶œ"""
    try:
        print("Camelotìœ¼ë¡œ í…Œì´ë¸” ì¶”ì¶œ ì¤‘...")
        tables = camelot.read_pdf(pdf_path, pages='all', flavor='stream')
        
        text = ""
        for i, table in enumerate(tables):
            text += f"\n--- í…Œì´ë¸” {i+1} ---\n"
            text += table.df.to_string(index=False)
            text += "\n"
        
        return text
    except Exception as e:
        print(f"Camelot ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None

def extract_tables_with_tabula(pdf_path):
    """Tabulaë¥¼ ì‚¬ìš©í•œ í…Œì´ë¸” ì¶”ì¶œ"""
    try:
        print("Tabulaë¡œ í…Œì´ë¸” ì¶”ì¶œ ì¤‘...")
        tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)
        
        text = ""
        for i, table in enumerate(tables):
            text += f"\n--- í…Œì´ë¸” {i+1} ---\n"
            text += table.to_string(index=False)
            text += "\n"
        
        return text
    except Exception as e:
        print(f"Tabula ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None

def extract_with_pypdf2(pdf_path):
    """PyPDF2ë¥¼ ì‚¬ìš©í•œ ì¶”ì¶œ"""
    try:
        print("PyPDF2ë¡œ ì¶”ì¶œ ì¤‘...")
        text = ""
        
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text()
                text += f"\n--- í˜ì´ì§€ {page_num + 1} ---\n{page_text}"
        
        return text
    except Exception as e:
        print(f"PyPDF2 ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None

def clean_and_merge_texts(*texts):
    """ì—¬ëŸ¬ ì¶”ì¶œ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê³  ë³‘í•©"""
    merged = ""
    
    for text in texts:
        if text:
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì²˜ë¦¬
            lines = text.split('\n')
            cleaned_lines = []
            
            for line in lines:
                line = line.strip()
                if line and line not in cleaned_lines:
                    cleaned_lines.append(line)
            
            merged += '\n'.join(cleaned_lines) + '\n\n'
    
    return merged

def parse_questions_comprehensive(text):
    """í¬ê´„ì ì¸ ë¬¸ì œ íŒŒì‹±"""
    questions = []
    
    # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„í• 
    lines = text.split('\n')
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # ë¬¸ì œ ë²ˆí˜¸ íŒ¨í„´ ì°¾ê¸°
        num_match = re.match(r'^(\d+)\s*[\.ë²ˆ]?\s*(.*)$', line)
        if num_match:
            q_num = int(num_match.group(1))
            q_text = num_match.group(2).strip()
            
            # ë¬¸ì œ ë‚´ìš©ì´ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ìŒ ì¤„ì—ì„œ ì°¾ê¸°
            if not q_text and i + 1 < len(lines):
                q_text = lines[i + 1].strip()
                i += 1
            
            # ì„ íƒì§€ ì°¾ê¸°
            choices = {}
            j = i + 1
            
            while j < len(lines) and len(choices) < 4:
                choice_line = lines[j].strip()
                
                # ì„ íƒì§€ íŒ¨í„´
                for choice_num in ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£']:
                    if choice_num in choice_line:
                        # ì„ íƒì§€ ë‚´ìš© ì¶”ì¶œ
                        idx = choice_line.find(choice_num)
                        choice_text = choice_line[idx + len(choice_num):].strip()
                        
                        # ë‹¤ìŒ ì„ íƒì§€ ë²ˆí˜¸ê°€ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ì˜ ë‚´ìš© í¬í•¨
                        k = j + 1
                        while k < len(lines):
                            next_line = lines[k].strip()
                            if any(cn in next_line for cn in ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£']) or re.match(r'^\d+[\.ë²ˆ]', next_line):
                                break
                            if next_line:
                                choice_text += ' ' + next_line
                            k += 1
                        
                        choices[choice_num] = choice_text.strip()
                
                j += 1
            
            # 4ê°œì˜ ì„ íƒì§€ê°€ ëª¨ë‘ ìˆìœ¼ë©´ ë¬¸ì œë¡œ ì¶”ê°€
            if len(choices) == 4 and q_text:
                questions.append({
                    'number': q_num,
                    'question': q_text,
                    'choices': choices
                })
        
        i += 1
    
    return questions

def find_answers_in_text(text, questions):
    """í…ìŠ¤íŠ¸ì—ì„œ ì •ë‹µ ì°¾ê¸°"""
    # ì •ë‹µ ì„¹ì…˜ ì°¾ê¸°
    answer_section = ""
    
    # ë‹¤ì–‘í•œ ì •ë‹µ ì„¹ì…˜ íŒ¨í„´
    patterns = [
        r'ì •ë‹µ\s*[:ï¼š]',
        r'ë‹µ\s*[:ï¼š]',
        r'í•´ë‹µ\s*[:ï¼š]',
        r'ì •ë‹µí‘œ',
        r'ë‹µì•ˆ'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            answer_section = text[match.end():]
            break
    
    # ê° ë¬¸ì œì˜ ì •ë‹µ ì°¾ê¸°
    for q in questions:
        q_num = q['number']
        
        # ì •ë‹µ íŒ¨í„´ë“¤
        answer_patterns = [
            rf'{q_num}\s*[ë²ˆ\.]?\s*[:\-]?\s*([â‘ â‘¡â‘¢â‘£])',
            rf'{q_num}\s*[ë²ˆ\.]?\s*ì •ë‹µ\s*[:\-]?\s*([â‘ â‘¡â‘¢â‘£])',
            rf'ë¬¸ì œ\s*{q_num}\s*[:\-]?\s*([â‘ â‘¡â‘¢â‘£])',
        ]
        
        for pattern in answer_patterns:
            match = re.search(pattern, answer_section if answer_section else text)
            if match:
                q['answer'] = match.group(1)
                break
    
    return questions

def save_final_result(questions, output_path):
    """ìµœì¢… ê²°ê³¼ ì €ì¥"""
    markdown = "# ì œ5íšŒ ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œ\n\n"
    markdown += f"**ì¶”ì¶œ ì™„ë£Œ**: {len(questions)}ë¬¸ì œ\n"
    markdown += f"**ì¶”ì¶œ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    markdown += f"**ì¶”ì¶œ ë°©ë²•**: ë‹¤ì¤‘ PDF ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¡°í•©\n\n"
    markdown += "---\n\n"
    
    # ê³¼ëª©ë³„ë¡œ ë¶„ë¥˜
    subjects = {
        'ìˆ˜ëª©ë³‘ë¦¬í•™': range(1, 31),
        'ìˆ˜ëª©í•´ì¶©í•™': range(31, 61),
        'ìˆ˜ëª©ìƒë¦¬í•™': range(61, 91),
        'ì‚°ë¦¼í† ì–‘í•™': range(91, 121),
        'ìˆ˜ëª©ê´€ë¦¬í•™': range(121, 151)
    }
    
    for subject, q_range in subjects.items():
        markdown += f"## {subject}\n\n"
        
        subject_questions = [q for q in questions if q['number'] in q_range]
        
        for q in subject_questions:
            markdown += f"### {q['number']}. {q['question']}\n\n"
            
            for choice_num, choice_text in q['choices'].items():
                markdown += f"{choice_num} {choice_text}\n"
            
            if 'answer' in q:
                markdown += f"\n**ì •ë‹µ: {q['answer']}**\n"
            
            markdown += "\n---\n\n"
    
    # í†µê³„
    markdown += "\n## ì¶”ì¶œ í†µê³„\n\n"
    markdown += f"- ì´ ë¬¸ì œ ìˆ˜: {len(questions)}\n"
    
    for subject, q_range in subjects.items():
        count = len([q for q in questions if q['number'] in q_range])
        markdown += f"- {subject}: {count}/{len(q_range)}ë¬¸ì œ\n"
    
    with_answer = sum(1 for q in questions if 'answer' in q)
    markdown += f"\n- ì •ë‹µ í¬í•¨: {with_answer}/{len(questions)}ë¬¸ì œ\n"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(markdown)
    
    return markdown

def main():
    pdf_path = '/Users/voidlight/Downloads/[Codekiller]ì œ5íšŒ ê¸°ì¶œë¬¸ì œ í•´ì„¤ì§‘(v1.0).pdf'
    output_path = '/Users/voidlight/tree-doctor-pdf-qa-mcp/data/exam-5th-perfect.md'
    
    print('ğŸŒ³ ì œ5íšŒ ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œ ì™„ë²½ ì¶”ì¶œ ì‹œì‘\n')
    
    # 1. ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("1ë‹¨ê³„: ë‹¤ì¤‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    
    texts = []
    
    # PDFMiner ì¶”ì¶œ
    pdfminer_text = extract_with_pdfminer(pdf_path)
    if pdfminer_text:
        texts.append(pdfminer_text)
        print("âœ“ PDFMiner ì¶”ì¶œ ì™„ë£Œ")
    
    # PyPDF2 ì¶”ì¶œ
    pypdf2_text = extract_with_pypdf2(pdf_path)
    if pypdf2_text:
        texts.append(pypdf2_text)
        print("âœ“ PyPDF2 ì¶”ì¶œ ì™„ë£Œ")
    
    # í…Œì´ë¸” ì¶”ì¶œ
    camelot_text = extract_tables_with_camelot(pdf_path)
    if camelot_text:
        texts.append(camelot_text)
        print("âœ“ Camelot í…Œì´ë¸” ì¶”ì¶œ ì™„ë£Œ")
    
    tabula_text = extract_tables_with_tabula(pdf_path)
    if tabula_text:
        texts.append(tabula_text)
        print("âœ“ Tabula í…Œì´ë¸” ì¶”ì¶œ ì™„ë£Œ")
    
    # 2. í…ìŠ¤íŠ¸ ë³‘í•© ë° ì •ë¦¬
    print("\n2ë‹¨ê³„: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë³‘í•© ë° ì •ë¦¬")
    merged_text = clean_and_merge_texts(*texts)
    
    if not merged_text:
        print("âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
        return
    
    # 3. ë¬¸ì œ íŒŒì‹±
    print("\n3ë‹¨ê³„: ë¬¸ì œ êµ¬ì¡° íŒŒì‹±")
    questions = parse_questions_comprehensive(merged_text)
    
    # 4. ì •ë‹µ ì°¾ê¸°
    print("\n4ë‹¨ê³„: ì •ë‹µ ì •ë³´ ì¶”ì¶œ")
    questions = find_answers_in_text(merged_text, questions)
    
    # 5. ê²°ê³¼ ì €ì¥
    print("\n5ë‹¨ê³„: ê²°ê³¼ ì €ì¥")
    save_final_result(questions, output_path)
    
    # ë””ë²„ê¹…ìš© ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥
    debug_path = output_path.replace('.md', '-debug.txt')
    with open(debug_path, 'w', encoding='utf-8') as f:
        f.write(merged_text)
    
    # 6. ìµœì¢… í†µê³„
    print(f"\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ!")
    print(f"- ì´ {len(questions)}ë¬¸ì œ ì¶”ì¶œ")
    print(f"- ì •ë‹µ í¬í•¨: {sum(1 for q in questions if 'answer' in q)}ë¬¸ì œ")
    print(f"- ì €ì¥ ìœ„ì¹˜: {output_path}")
    
    # ëˆ„ë½ëœ ë¬¸ì œ í™•ì¸
    if len(questions) < 150:
        missing = []
        extracted_nums = [q['number'] for q in questions]
        for i in range(1, 151):
            if i not in extracted_nums:
                missing.append(i)
        
        if missing:
            print(f"\nâš ï¸ ëˆ„ë½ëœ ë¬¸ì œ: {len(missing)}ê°œ")
            print(f"   {missing[:10]}{'...' if len(missing) > 10 else ''}")

if __name__ == '__main__':
    main()