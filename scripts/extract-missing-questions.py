#!/usr/bin/env python3
"""
ëˆ„ë½ëœ ê¸°ì¶œë¬¸ì œë¥¼ ì¶”ì¶œí•˜ê³  í…ìŠ¤íŠ¸í™”í•˜ëŠ” ì „ëµ
"""

import os
import json
import sqlite3
from pathlib import Path
from datetime import datetime

class MissingQuestionExtractor:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.data_dir = self.project_root / "data"
        self.db_path = self.project_root / "tree-doctor-pdf-qa.db"
        
    def analyze_missing_questions(self):
        """ëˆ„ë½ëœ ë¬¸ì œ ë¶„ì„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # íšŒì°¨ë³„ í˜„í™©
        cursor.execute("""
            SELECT exam_year, COUNT(*) as current, 
                   150 - COUNT(*) as missing
            FROM exam_questions 
            GROUP BY exam_year
            ORDER BY exam_year
        """)
        
        results = cursor.fetchall()
        conn.close()
        
        report = {
            "analysis_date": datetime.now().isoformat(),
            "total_target": 750,  # 5íšŒì°¨ * 150ë¬¸ì œ
            "current_total": sum(r[1] for r in results),
            "missing_total": sum(r[2] for r in results),
            "rounds": {}
        }
        
        for year, current, missing in results:
            report["rounds"][f"{year}íšŒ"] = {
                "current": current,
                "target": 150,
                "missing": missing,
                "completion_rate": f"{(current/150)*100:.1f}%"
            }
            
        return report

    def create_extraction_strategies(self):
        """íšŒì°¨ë³„ ì¶”ì¶œ ì „ëµ"""
        strategies = {
            "5íšŒ": {
                "status": "PDF ì—†ìŒ",
                "strategy": "ëŒ€ì²´ ìë£Œ í•„ìš”",
                "actions": [
                    "ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë¬¸ì œ ìˆ˜ì§‘",
                    "ê¸°ì¶œë¬¸ì œì§‘ êµ¬ë§¤ í›„ ìˆ˜ë™ ì…ë ¥",
                    "Discord/ì¹´í˜ì—ì„œ ìë£Œ ìš”ì²­"
                ]
            },
            "6íšŒ": {
                "status": "41ë¬¸ì œ ëˆ„ë½",
                "strategy": "ë¶€ë¶„ ë³µêµ¬ ê°€ëŠ¥",
                "actions": [
                    "ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì¬ê²€í† ",
                    "ì´ë¯¸ì§€ OCR ì¬ì‹œë„",
                    "ìˆ˜ë™ìœ¼ë¡œ ëˆ„ë½ ë¬¸ì œ ì…ë ¥"
                ]
            },
            "7íšŒ": {
                "status": "145ë¬¸ì œ ëˆ„ë½",
                "strategy": "ì „ë©´ ì¬ì‘ì—… í•„ìš”",
                "actions": [
                    "ì›ë³¸ PDF ì¬í™•ë³´",
                    "ê³ í’ˆì§ˆ OCR ë„êµ¬ ì‚¬ìš©",
                    "í˜ì´ì§€ë³„ ìˆ˜ë™ ê²€ì¦"
                ]
            },
            "8íšŒ": {
                "status": "145ë¬¸ì œ ëˆ„ë½",
                "strategy": "ì „ë©´ ì¬ì‘ì—… í•„ìš”",
                "actions": [
                    "ë§ˆí¬ë‹¤ìš´ íŒŒì¼ êµ¬ì¡° ë¶„ì„",
                    "ë¬¸ì œ íŒ¨í„´ ì¸ì‹ ê°œì„ ",
                    "ì„ íƒì§€ ì¶”ì¶œ ë¡œì§ ìˆ˜ì •"
                ]
            },
            "9íšŒ": {
                "status": "91ë¬¸ì œ ëˆ„ë½",
                "strategy": "ë¶€ë¶„ ë³´ì™„",
                "actions": [
                    "ê¸°ì¡´ 59ë¬¸ì œ í’ˆì§ˆ ê²€ì¦",
                    "ëˆ„ë½ êµ¬ê°„ ì§‘ì¤‘ ì¶”ì¶œ",
                    "ë¬¸ì œ ë²ˆí˜¸ ì—°ì†ì„± í™•ì¸"
                ]
            },
            "10íšŒ": {
                "status": "ì™„ë£Œ",
                "strategy": "í’ˆì§ˆ ê°œì„ ë§Œ",
                "actions": [
                    "ì„ íƒì§€ ì •í™•ë„ ê²€ì¦",
                    "ì •ë‹µ í™•ì¸",
                    "í•´ì„¤ ì¶”ê°€"
                ]
            },
            "11íšŒ": {
                "status": "120ë¬¸ì œ ëˆ„ë½",
                "strategy": "ëŒ€ê·œëª¨ ë³´ì™„ í•„ìš”",
                "actions": [
                    "125ë¬¸ì œ í˜•ì‹ í™•ì¸",
                    "ëˆ„ë½ ë¬¸ì œ ì§‘ì¤‘ ì¶”ì¶œ",
                    "ìµœì¢… ê²€ì¦"
                ]
            }
        }
        
        return strategies

    def create_manual_input_template(self):
        """ìˆ˜ë™ ì…ë ¥ìš© í…œí”Œë¦¿ ìƒì„±"""
        template = {
            "exam_year": 0,
            "question_number": 0,
            "subject": "ê³¼ëª© ì„ íƒ: ìˆ˜ëª©ë³‘ë¦¬í•™/ìˆ˜ëª©í•´ì¶©í•™/ìˆ˜ëª©ìƒë¦¬í•™/ìˆ˜ëª©ê´€ë¦¬í•™/ì„ì—…ì¼ë°˜/í† ì–‘í•™",
            "question_text": "ë¬¸ì œ ë‚´ìš©ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”",
            "choices": {
                "1": "ì²« ë²ˆì§¸ ì„ íƒì§€",
                "2": "ë‘ ë²ˆì§¸ ì„ íƒì§€",
                "3": "ì„¸ ë²ˆì§¸ ì„ íƒì§€",
                "4": "ë„¤ ë²ˆì§¸ ì„ íƒì§€"
            },
            "answer": 0,
            "explanation": "í•´ì„¤ (ì„ íƒì‚¬í•­)",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
        }
        
        # í…œí”Œë¦¿ íŒŒì¼ ìƒì„±
        template_path = self.data_dir / "manual-input-template.json"
        with open(template_path, 'w', encoding='utf-8') as f:
            json.dump(template, f, ensure_ascii=False, indent=2)
            
        return template_path

    def create_ocr_improvement_script(self):
        """OCR ê°œì„  ìŠ¤í¬ë¦½íŠ¸"""
        script = '''#!/usr/bin/env python3
"""
ê°œì„ ëœ OCR ìŠ¤í¬ë¦½íŠ¸ - Tesseract + í›„ì²˜ë¦¬
"""

import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import numpy as np

def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¡œ OCR ì •í™•ë„ í–¥ìƒ"""
    # ì´ë¯¸ì§€ ë¡œë“œ
    img = cv2.imread(image_path)
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # ë…¸ì´ì¦ˆ ì œê±°
    denoised = cv2.fastNlMeansDenoising(gray)
    
    # ëŒ€ë¹„ í–¥ìƒ
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(denoised)
    
    # ì´ì§„í™”
    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    return binary

def extract_text_with_layout(image_path):
    """ë ˆì´ì•„ì›ƒ ë³´ì¡´í•˜ë©° í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    # ì „ì²˜ë¦¬
    processed = preprocess_image(image_path)
    
    # Tesseract ì„¤ì •
    custom_config = r'--oem 3 --psm 6 -l kor+eng'
    
    # OCR ì‹¤í–‰
    text = pytesseract.image_to_string(processed, config=custom_config)
    
    # í›„ì²˜ë¦¬
    text = post_process_text(text)
    
    return text

def post_process_text(text):
    """OCR ê²°ê³¼ í›„ì²˜ë¦¬"""
    # ì¼ë°˜ì ì¸ OCR ì˜¤ë¥˜ ìˆ˜ì •
    corrections = {
        'ë®¤íš¨': 'ìœ íš¨',
        'ëª¬ë„': 'ì˜¨ë„',
        '0)': 'â‘ ',
        'Â®': 'â‘¡',
        'Â©': 'â‘¢',
        '@': 'â‘£',
        'Â®': 'â‘¤'
    }
    
    for wrong, correct in corrections.items():
        text = text.replace(wrong, correct)
        
    return text

def extract_questions_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œ êµ¬ì¡° ì¶”ì¶œ"""
    import re
    
    questions = []
    
    # ë¬¸ì œ íŒ¨í„´
    question_pattern = r'(\d+)\s*[.)]\s*(.+?)(?=\d+\s*[.)]|$)'
    
    matches = re.finditer(question_pattern, text, re.DOTALL)
    
    for match in matches:
        q_num = match.group(1)
        q_text = match.group(2).strip()
        
        # ì„ íƒì§€ ì¶”ì¶œ
        choices = {}
        choice_pattern = r'([â‘ â‘¡â‘¢â‘£â‘¤])\s*(.+?)(?=[â‘ â‘¡â‘¢â‘£â‘¤]|ì •ë‹µ|$)'
        choice_matches = re.finditer(choice_pattern, q_text)
        
        for c_match in choice_matches:
            choice_num = c_match.group(1)
            choice_text = c_match.group(2).strip()
            choices[choice_num] = choice_text
            
        questions.append({
            'number': int(q_num),
            'text': q_text.split('â‘ ')[0].strip(),
            'choices': choices
        })
        
    return questions
'''
        
        script_path = self.data_dir / "improved_ocr_extractor.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script)
            
        return script_path

    def create_crowdsourcing_template(self):
        """í¬ë¼ìš°ë“œì†Œì‹±ìš© GitHub ì´ìŠˆ í…œí”Œë¦¿"""
        template = """---
name: ê¸°ì¶œë¬¸ì œ ì…ë ¥
about: ëˆ„ë½ëœ ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”
title: '[ë¬¸ì œì…ë ¥] XíšŒ Xë²ˆ ë¬¸ì œ'
labels: ['contribution', 'exam-questions']
---

## ë¬¸ì œ ì •ë³´
- **íšŒì°¨**: XíšŒ
- **ë¬¸ì œ ë²ˆí˜¸**: Xë²ˆ
- **ê³¼ëª©**: 

## ë¬¸ì œ ë‚´ìš©
```
ì—¬ê¸°ì— ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”
```

## ì„ íƒì§€
- â‘  
- â‘¡ 
- â‘¢ 
- â‘£ 

## ì •ë‹µ
- ì •ë‹µ: Xë²ˆ

## í•´ì„¤ (ì„ íƒì‚¬í•­)
```
í•´ì„¤ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”
```

## ì¶œì²˜
- [ ] ê³µì‹ ê¸°ì¶œë¬¸ì œì§‘
- [ ] ìˆ˜í—˜ì„œ
- [ ] ê¸°íƒ€: 

---
**ê¸°ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸŒ³**
"""
        
        template_path = self.project_root / ".github" / "ISSUE_TEMPLATE" / "add-question.md"
        template_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(template_path, 'w', encoding='utf-8') as f:
            f.write(template)
            
        return template_path

    def generate_completion_plan(self):
        """ì™„ì„± ê³„íš ìƒì„±"""
        analysis = self.analyze_missing_questions()
        strategies = self.create_extraction_strategies()
        
        plan = {
            "project": "ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œ ì™„ì„± í”„ë¡œì íŠ¸",
            "current_status": analysis,
            "strategies": strategies,
            "timeline": {
                "Phase 1 (1ì£¼)": [
                    "ìˆ˜ë™ ì…ë ¥ í…œí”Œë¦¿ ë°°í¬",
                    "GitHub ì´ìŠˆ í…œí”Œë¦¿ ì„¤ì •",
                    "Discord ì»¤ë®¤ë‹ˆí‹° ê°œì„¤"
                ],
                "Phase 2 (2ì£¼)": [
                    "OCR ë„êµ¬ ê°œì„ ",
                    "ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ ì¬ë¶„ì„",
                    "ë¶€ë¶„ ì™„ì„± íšŒì°¨(6, 9íšŒ) ë³´ì™„"
                ],
                "Phase 3 (4ì£¼)": [
                    "í¬ë¼ìš°ë“œì†Œì‹± ì‹œì‘",
                    "ëŒ€ëŸ‰ ëˆ„ë½ íšŒì°¨(7, 8, 11íšŒ) ì‘ì—…",
                    "í’ˆì§ˆ ê²€ì¦"
                ],
                "Phase 4 (2ì£¼)": [
                    "ìµœì¢… ê²€ì¦",
                    "ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸",
                    "ë°°í¬"
                ]
            },
            "resources_needed": [
                "ì›ë³¸ PDF íŒŒì¼",
                "ê³ í’ˆì§ˆ OCR ë„êµ¬ (Google Vision API ë“±)",
                "ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ì",
                "ê²€ì¦ ì¸ë ¥"
            ]
        }
        
        # ê³„íšì„œ ì €ì¥
        plan_path = self.project_root / "COMPLETION_PLAN.md"
        with open(plan_path, 'w', encoding='utf-8') as f:
            f.write(f"# ë‚˜ë¬´ì˜ì‚¬ ê¸°ì¶œë¬¸ì œ ì™„ì„± ê³„íš\n\n")
            f.write(f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d')}\n\n")
            f.write("## í˜„ì¬ ìƒí™©\n")
            f.write(f"- ì „ì²´ ëª©í‘œ: 750ë¬¸ì œ (5íšŒì°¨ Ã— 150ë¬¸ì œ)\n")
            f.write(f"- í˜„ì¬ ë³´ìœ : {analysis['current_total']}ë¬¸ì œ\n")
            f.write(f"- ëˆ„ë½: {analysis['missing_total']}ë¬¸ì œ\n\n")
            
            f.write("## íšŒì°¨ë³„ ìƒí™©\n")
            for round_name, data in analysis['rounds'].items():
                f.write(f"### {round_name}\n")
                f.write(f"- í˜„ì¬: {data['current']}/{data['target']}ë¬¸ì œ\n")
                f.write(f"- ì™„ì„±ë„: {data['completion_rate']}\n")
                f.write(f"- ì „ëµ: {strategies[round_name]['strategy']}\n\n")
                
        return plan_path

# ì‹¤í–‰
if __name__ == "__main__":
    extractor = MissingQuestionExtractor()
    
    print("ğŸ“Š ëˆ„ë½ ë¬¸ì œ ë¶„ì„ ì¤‘...")
    analysis = extractor.analyze_missing_questions()
    print(json.dumps(analysis, ensure_ascii=False, indent=2))
    
    print("\nğŸ“ í…œí”Œë¦¿ ìƒì„± ì¤‘...")
    template_path = extractor.create_manual_input_template()
    print(f"âœ… ìˆ˜ë™ ì…ë ¥ í…œí”Œë¦¿: {template_path}")
    
    print("\nğŸ”§ OCR ê°œì„  ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
    ocr_path = extractor.create_ocr_improvement_script()
    print(f"âœ… OCR ìŠ¤í¬ë¦½íŠ¸: {ocr_path}")
    
    print("\nğŸ‘¥ í¬ë¼ìš°ë“œì†Œì‹± í…œí”Œë¦¿ ìƒì„± ì¤‘...")
    crowd_path = extractor.create_crowdsourcing_template()
    print(f"âœ… GitHub ì´ìŠˆ í…œí”Œë¦¿: {crowd_path}")
    
    print("\nğŸ“‹ ì™„ì„± ê³„íš ìƒì„± ì¤‘...")
    plan_path = extractor.generate_completion_plan()
    print(f"âœ… ì™„ì„± ê³„íšì„œ: {plan_path}")