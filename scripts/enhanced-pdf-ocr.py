#!/usr/bin/env python3
"""
í–¥ìƒëœ PDF OCR ì¶”ì¶œê¸°
ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¡°í•©í•œ ìµœì í™”ëœ ë¬¸ì œ ì¶”ì¶œ
"""

import os
import re
import json
import sqlite3
from pathlib import Path
import pdfplumber
import pytesseract
from PIL import Image
import fitz  # PyMuPDF
from pdf2image import convert_from_path

class EnhancedPDFOCR:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.data_dir = self.project_root / "data"
        self.db_path = self.project_root / "tree-doctor-pdf-qa.db"
        self.temp_dir = self.project_root / "temp_ocr"
        self.temp_dir.mkdir(exist_ok=True)
        
    def extract_with_pdfplumber(self, pdf_path):
        """pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        print("ğŸ“– pdfplumberë¡œ ì¶”ì¶œ ì¤‘...")
        text = ""
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n\n--- í˜ì´ì§€ {i+1} ---\n\n"
                        text += page_text
        except Exception as e:
            print(f"âš ï¸ pdfplumber ì˜¤ë¥˜: {e}")
        
        return text
    
    def extract_with_pymupdf(self, pdf_path):
        """PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        print("ğŸ“– PyMuPDFë¡œ ì¶”ì¶œ ì¤‘...")
        text = ""
        
        try:
            pdf = fitz.open(pdf_path)
            for i, page in enumerate(pdf):
                page_text = page.get_text()
                if page_text:
                    text += f"\n\n--- í˜ì´ì§€ {i+1} ---\n\n"
                    text += page_text
            pdf.close()
        except Exception as e:
            print(f"âš ï¸ PyMuPDF ì˜¤ë¥˜: {e}")
        
        return text
    
    def extract_with_ocr(self, pdf_path):
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCR"""
        print("ğŸ” OCRë¡œ ì¶”ì¶œ ì¤‘...")
        text = ""
        
        try:
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            images = convert_from_path(str(pdf_path), dpi=300)
            
            for i, image in enumerate(images):
                print(f"  í˜ì´ì§€ {i+1}/{len(images)} OCR ì²˜ë¦¬ ì¤‘...")
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                image = image.convert('L')  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
                
                # OCR ìˆ˜í–‰
                page_text = pytesseract.image_to_string(image, lang='kor')
                if page_text:
                    text += f"\n\n--- í˜ì´ì§€ {i+1} ---\n\n"
                    text += page_text
        except Exception as e:
            print(f"âš ï¸ OCR ì˜¤ë¥˜: {e}")
        
        return text
    
    def combine_extractions(self, pdf_path):
        """ì—¬ëŸ¬ ë°©ë²•ì„ ì¡°í•©í•˜ì—¬ ìµœì ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        print(f"\nğŸ“„ PDF ì²˜ë¦¬: {pdf_path.name}")
        
        # 1. pdfplumber ì‹œë„
        text1 = self.extract_with_pdfplumber(pdf_path)
        
        # 2. PyMuPDF ì‹œë„
        text2 = self.extract_with_pymupdf(pdf_path)
        
        # 3. í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ë©´ OCR ì‹œë„
        if len(text1) < 1000 and len(text2) < 1000:
            print("âš ï¸ ì¼ë°˜ ì¶”ì¶œ ê²°ê³¼ ë¶€ì¡±, OCR ì‹œë„...")
            text3 = self.extract_with_ocr(pdf_path)
            return text3
        
        # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ ì„ íƒ
        return text1 if len(text1) > len(text2) else text2
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬ ë° OCR ì˜¤ë¥˜ ìˆ˜ì •"""
        # OCR ì˜¤ë¥˜ íŒ¨í„´ ìˆ˜ì •
        corrections = {
            # ë²ˆí˜¸ ê´€ë ¨
            'â‘ ': 'â‘ ', 'â‘¡': 'â‘¡', 'â‘¢': 'â‘¢', 'â‘£': 'â‘£', 'â‘¤': 'â‘¤',
            'Â©': 'â‘ ', 'Â®': 'â‘¡', 'Âº': 'â‘¢', 'Â¼': 'â‘£', 'Â½': 'â‘¤',
            '(1)': 'â‘ ', '(2)': 'â‘¡', '(3)': 'â‘¢', '(4)': 'â‘£', '(5)': 'â‘¤',
            
            # í•œê¸€ ì˜¤ë¥˜
            'ë®¤íš¨': 'ìœ íš¨', 'ëª¬ë„': 'ì˜¨ë„', 'íŠ¸ë ˆìŠ¤': 'ìŠ¤íŠ¸ë ˆìŠ¤',
            'ì‹œëŸ¬': 'ì‹¤ëŸ¬', 'ì¹ ì—½': 'ì¹ ì—½', 'ê·¼ë‘ì•”ì´ë³‘': 'ê·¼ë‘ì•”ì¢…ë³‘',
            
            # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
            'â€“': '-', 'â€”': '-', '"': '"', '"': '"', ''': "'", ''': "'",
            'â€¦': '...', 'ï½¥': 'Â·',
        }
        
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text
    
    def extract_questions(self, text, exam_year):
        """ë¬¸ì œ ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)"""
        questions = []
        
        # í˜ì´ì§€ë³„ë¡œ ì²˜ë¦¬
        pages = text.split('--- í˜ì´ì§€')
        
        for page_text in pages:
            # ë¬¸ì œ ë²ˆí˜¸ ì°¾ê¸° - ë‹¤ì–‘í•œ íŒ¨í„´
            patterns = [
                # ê¸°ë³¸ íŒ¨í„´
                r'(\d{1,3})\.\s*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
                r'(\d{1,3})\)\s*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
                r'ë¬¸ì œ\s*(\d{1,3})[.)\s]*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
                
                # íŠ¹ìˆ˜ íŒ¨í„´
                r'ã€\s*(\d{1,3})\s*ã€‘\s*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
                r'Q(\d{1,3})[.)\s]*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
                r'\[(\d{1,3})\]\s*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
            ]
            
            for pattern in patterns:
                matches = list(re.finditer(pattern, page_text, re.MULTILINE))
                
                for i, match in enumerate(matches):
                    q_num = int(match.group(1))
                    if 1 <= q_num <= 150:
                        # ë¬¸ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        q_text = match.group(2).strip()
                        
                        # ë‹¤ìŒ ë¬¸ì œê¹Œì§€ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
                        start_pos = match.end()
                        if i + 1 < len(matches):
                            end_pos = matches[i + 1].start()
                        else:
                            end_pos = len(page_text)
                        
                        full_text = page_text[start_pos:end_pos]
                        
                        # ì„ íƒì§€ ì¶”ì¶œ
                        choices = self.extract_choices(full_text)
                        
                        if len(choices) >= 4:
                            question = {
                                'number': q_num,
                                'text': self.clean_text(q_text),
                                'choices': choices,
                                'exam_year': exam_year,
                                'subject': self.detect_subject(q_text)
                            }
                            questions.append(question)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_questions = {}
        for q in questions:
            if q['number'] not in unique_questions:
                unique_questions[q['number']] = q
        
        return sorted(unique_questions.values(), key=lambda x: x['number'])
    
    def extract_choices(self, text):
        """ì„ íƒì§€ ì¶”ì¶œ"""
        choices = {}
        
        # ì„ íƒì§€ íŒ¨í„´ë“¤
        patterns = [
            r'([â‘ â‘¡â‘¢â‘£â‘¤])\s*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+)',
            r'([1-5])[.)]\s*([^1-5\n]+)',
            r'\(([1-5])\)\s*([^\(\)\n]+)',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                choice_num = self.normalize_choice_number(match.group(1))
                choice_text = match.group(2).strip()
                
                if choice_num and len(choice_text) > 2:
                    # ì •ë‹µì´ë‚˜ í•´ì„¤ ë¶€ë¶„ ì œê±°
                    if not re.search(r'ì •ë‹µ|í•´ì„¤|ë‹µì•ˆ|ì„¤ëª…', choice_text[:10]):
                        choices[choice_num] = choice_text
                
                if len(choices) >= 5:
                    break
        
        return choices
    
    def normalize_choice_number(self, num):
        """ì„ íƒì§€ ë²ˆí˜¸ ì •ê·œí™”"""
        mapping = {
            'â‘ ': 1, 'â‘¡': 2, 'â‘¢': 3, 'â‘£': 4, 'â‘¤': 5,
            '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
            'â‘´': 1, 'â‘µ': 2, 'â‘¶': 3, 'â‘·': 4, 'â‘¸': 5,
        }
        return mapping.get(num)
    
    def detect_subject(self, text):
        """ê³¼ëª© ë¶„ë¥˜ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        subjects = {
            'ìˆ˜ëª©ë³‘ë¦¬í•™': ['ë³‘ì›ì²´', 'ë³‘ì›ê· ', 'ê°ì—¼', 'ì„¸ê· ', 'ë°”ì´ëŸ¬ìŠ¤', 'ì§„ê· ', 'ê³°íŒ¡ì´', 
                      'ë³‘í•´', 'ì‚´ê· ì œ', 'ë³‘ì§•', 'ë³‘ë°˜', 'í°ê°€ë£¨ë³‘', 'íƒ„ì €ë³‘', 'ë§ˆë¦„ë³‘',
                      'ìë§ˆë¦„ë³‘', 'ì¤„ê¸°ì©ìŒë³‘', 'ë¿Œë¦¬ì©ìŒë³‘', 'ì‹œë“¤ìŒë³‘'],
            'ìˆ˜ëª©í•´ì¶©í•™': ['í•´ì¶©', 'ê³¤ì¶©', 'ì²œì ', 'ìœ ì¶©', 'ë²ˆë°ê¸°', 'ì„±ì¶©', 'ì‚´ì¶©ì œ', 
                      'ì²œê³µ', 'ê°€í•´', 'ë‚˜ë°©', 'ë”±ì •ë²Œë ˆ', 'ì§„ë”§ë¬¼', 'ê¹ì§€ë²Œë ˆ',
                      'ì‘ì• ', 'ë‚˜ë¬´ì¢€', 'í•˜ëŠ˜ì†Œ', 'ë°”êµ¬ë¯¸'],
            'ìˆ˜ëª©ìƒë¦¬í•™': ['ê´‘í•©ì„±', 'í˜¸í¡', 'ì¦ì‚°', 'ì˜ì–‘', 'ìƒì¥', 'ì‹ë¬¼í˜¸ë¥´ëª¬', 
                      'êµ´ê´‘ì„±', 'êµ´ì§€ì„±', 'ì˜¥ì‹ ', 'ì§€ë² ë ë¦°', 'ì‹œí† í‚¤ë‹Œ', 'ì—í‹¸ë Œ',
                      'ABA', 'ì•±ì‹œìŠ¤ì‚°', 'ê¸°ê³µ', 'ë¬¼ê´€', 'ì²´ê´€'],
            'ìˆ˜ëª©ê´€ë¦¬í•™': ['ì „ì •', 'ì‹œë¹„', 'ê´€ë¦¬', 'ì§„ë‹¨', 'ì‹ì¬', 'ì´ì‹', 'ë©€ì¹­', 
                      'ì „ì§€', 'ê°€ì§€ì¹˜ê¸°', 'ë³‘ì¶©í•´ë°©ì œ', 'ìˆ˜ëª©ì§„ë‹¨', 'í† ì–‘ê°œëŸ‰',
                      'ì§€ì£¼ëŒ€', 'ê´€ìˆ˜', 'ì›”ë™'],
            'í† ì–‘í•™': ['í† ì–‘', 'pH', 'ì–‘ë¶„', 'ë¹„ë£Œ', 'ìœ ê¸°ë¬¼', 'ë°°ìˆ˜', 'í†µê¸°ì„±', 
                   'ì–‘ì´ì˜¨êµí™˜', 'ë¶€ì‹', 'í† ì„±', 'ì…ë‹¨', 'ê³µê·¹', 'ìš©ì ë°€ë„'],
            'ì„ì—…ì¼ë°˜': ['ì‚°ë¦¼', 'ì¡°ë¦¼', 'ë²Œì±„', 'ê°±ì‹ ', 'ì„ë¶„', 'ì„ëª©', 'ì²œì—°ê°±ì‹ ', 
                    'ì¸ê³µì¡°ë¦¼', 'ìœ¡ë¦¼', 'ì‚°ë¦¼ê²½ì˜', 'ì„ë ¹', 'ìˆ˜í™•', 'ê°„ë²Œ']
        }
        
        # ê° ê³¼ëª©ë³„ ì ìˆ˜ ê³„ì‚°
        scores = {}
        for subject, keywords in subjects.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > 0:
                scores[subject] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê³¼ëª© ë°˜í™˜
        if scores:
            return max(scores, key=scores.get)
        
        return 'ë¯¸ë¶„ë¥˜'
    
    def save_to_database(self, questions):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved = 0
        skipped = 0
        
        for q in questions:
            # ì¤‘ë³µ í™•ì¸
            cursor.execute(
                "SELECT id FROM exam_questions WHERE exam_year = ? AND question_number = ?",
                (q['exam_year'], q['number'])
            )
            
            if cursor.fetchone():
                skipped += 1
                continue
            
            try:
                # ë¬¸ì œ ì €ì¥
                cursor.execute("""
                    INSERT INTO exam_questions (
                        exam_year, exam_round, question_number, subject,
                        question_text, question_type, points, is_incomplete
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    q['exam_year'], 1, q['number'], q['subject'],
                    q['text'], 'multiple_choice', 1, 0
                ))
                
                question_id = cursor.lastrowid
                
                # ì„ íƒì§€ ì €ì¥
                for num, text in q['choices'].items():
                    cursor.execute("""
                        INSERT INTO exam_choices (
                            question_id, choice_number, choice_text, is_correct
                        ) VALUES (?, ?, ?, ?)
                    """, (question_id, num, text, 0))
                
                saved += 1
                
                if saved % 10 == 0:
                    conn.commit()
                    print(f"ğŸ’¾ {saved}ê°œ ì €ì¥ ì¤‘...")
                    
            except Exception as e:
                print(f"âš ï¸ ë¬¸ì œ {q['number']} ì €ì¥ ì˜¤ë¥˜: {e}")
        
        conn.commit()
        conn.close()
        
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {saved}ê°œ ì¶”ê°€, {skipped}ê°œ ì¤‘ë³µ ì œì™¸")
        return saved, skipped
    
    def show_stats(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ í‘œì‹œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT exam_year, COUNT(*) as count 
            FROM exam_questions 
            GROUP BY exam_year 
            ORDER BY exam_year
        """)
        
        print("\nğŸ“Š í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:")
        print("â”" * 40)
        
        total = 0
        for row in cursor.fetchall():
            percent = (row[1] / 150) * 100
            print(f"{row[0]}íšŒì°¨: {row[1]}/150 ({percent:.1f}%)")
            total += row[1]
        
        print("â”" * 40)
        print(f"ì „ì²´: {total}/750 ë¬¸ì œ")
        print()
        
        conn.close()
    
    def process_pdf(self, pdf_path, exam_year):
        """PDF íŒŒì¼ ì²˜ë¦¬"""
        print(f"\nğŸ¯ {exam_year}íšŒì°¨ ì²˜ë¦¬ ì‹œì‘...")
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = self.combine_extractions(pdf_path)
        
        # í…ìŠ¤íŠ¸ ì €ì¥
        output_txt = pdf_path.with_suffix('.extracted.txt')
        with open(output_txt, 'w', encoding='utf-8') as f:
            f.write(text)
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ì €ì¥: {output_txt.name}")
        
        # ë¬¸ì œ ì¶”ì¶œ
        questions = self.extract_questions(text, exam_year)
        print(f"ğŸ” {len(questions)}ê°œ ë¬¸ì œ ì¶”ì¶œë¨")
        
        # JSON ì €ì¥
        output_json = pdf_path.with_suffix('.questions.json')
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(questions, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“‹ JSON ì €ì¥: {output_json.name}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        saved, skipped = self.save_to_database(questions)
        
        return saved, skipped
    
    def run(self):
        """ì‹¤í–‰"""
        print("ğŸš€ í–¥ìƒëœ PDF OCR ì¶”ì¶œê¸° ì‹œì‘...\n")
        
        self.show_stats()
        
        # PDF íŒŒì¼ ëª©ë¡
        pdfs = [
            ('ì œ11íšŒ ë‚˜ë¬´ì˜ì‚¬ ìê²©ì‹œí—˜ 1ì°¨ ì‹œí—˜ì§€.pdf', 11),
            ('exam-10th.pdf', 10),
        ]
        
        total_saved = 0
        total_skipped = 0
        
        for pdf_name, exam_year in pdfs:
            pdf_path = self.data_dir / pdf_name
            if pdf_path.exists():
                saved, skipped = self.process_pdf(pdf_path, exam_year)
                total_saved += saved
                total_skipped += skipped
            else:
                print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {pdf_path}")
        
        print(f"\nğŸ“Š ì „ì²´ ê²°ê³¼:")
        print(f"ì´ {total_saved}ê°œ ì¶”ê°€, {total_skipped}ê°œ ì¤‘ë³µ ì œì™¸")
        
        self.show_stats()
        print("âœ… ì¶”ì¶œ ì™„ë£Œ!")

if __name__ == "__main__":
    extractor = EnhancedPDFOCR()
    extractor.run()